{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drewwint/psy535_dev_neuro_2024/blob/main/VBM_example_Nilearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_nMMVl9cWn6"
      },
      "source": [
        "\n",
        "# Voxel-Based Morphometry on OASIS dataset\n",
        "\n",
        "This example uses voxel-based morphometry (:term:`VBM`) to study the\n",
        "relationship between aging, sex, and gray matter density.\n",
        "\n",
        "The data come from the [OASIS](https://www.oasis-brains.org/) project.\n",
        "If you use it, you need to agree with the data usage agreement available\n",
        "on the website.\n",
        "\n",
        "It has been run through a standard :term:`VBM` pipeline\n",
        "(using SPM8 and NewSegment)\n",
        "to create :term:`VBM` maps, which we study here.\n",
        "\n",
        "## VBM analysis of aging\n",
        "\n",
        "We run a standard :term:`GLM` analysis\n",
        "to study the association between age and gray matter density\n",
        "from the :term:`VBM` data.\n",
        "We use only 100 subjects from the OASIS dataset to limit the memory usage.\n",
        "\n",
        "Note that more power would be obtained from using a larger sample of subjects.\n",
        "\n",
        "..\n",
        "    Original authors:\n",
        "\n",
        "    - Bertrand Thirion, <bertrand.thirion@inria.fr>, July 2018\n",
        "    - Elvis Dhomatob, Apr. 2014\n",
        "    - Virgile Fritsch, Apr 2014\n",
        "    - Gael Varoquaux, Apr 2014\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-BINfs2cWn_"
      },
      "source": [
        "## Load Oasis dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMG7KGfqcWoA"
      },
      "outputs": [],
      "source": [
        "from nilearn import datasets, plotting\n",
        "\n",
        "n_subjects = 100  # more subjects requires more memory\n",
        "\n",
        "oasis_dataset = datasets.fetch_oasis_vbm(\n",
        "    n_subjects=n_subjects,\n",
        "    legacy_format=False,\n",
        ")\n",
        "gray_matter_map_filenames = oasis_dataset.gray_matter_maps\n",
        "age = oasis_dataset.ext_vars[\"age\"].astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DHnrGmGcWoC"
      },
      "source": [
        "Sex is encoded as 'M' or 'F'. Hence, we make it a binary variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5ctVWwpcWoD"
      },
      "outputs": [],
      "source": [
        "sex = oasis_dataset.ext_vars[\"mf\"] == \"F\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbVJGD0mcWoD"
      },
      "source": [
        "Print basic information on the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYed1H9IcWoE"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"First gray-matter anatomy image (3D) is located at: \"\n",
        "    f\"{oasis_dataset.gray_matter_maps[0]}\"\n",
        ")\n",
        "print(\n",
        "    \"First white-matter anatomy image (3D) is located at: \"\n",
        "    f\"{oasis_dataset.white_matter_maps[0]}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjACmhMNcWoE"
      },
      "source": [
        "Get a mask image: A mask of the cortex of the ICBM template.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtdiEp5rcWoF"
      },
      "outputs": [],
      "source": [
        "gm_mask = datasets.fetch_icbm152_brain_gm_mask()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smxIrPiZcWoG"
      },
      "source": [
        "Resample the mask, since this mask has a different resolution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVNkjnjScWoH"
      },
      "outputs": [],
      "source": [
        "from nilearn.image import resample_to_img\n",
        "\n",
        "mask_img = resample_to_img(\n",
        "    gm_mask,\n",
        "    gray_matter_map_filenames[0],\n",
        "    interpolation=\"nearest\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb4oWAVjcWoI"
      },
      "source": [
        "## Analyse data\n",
        "First, we create an adequate design matrix with three columns: 'age', 'sex',\n",
        "and 'intercept'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjLS4tXKcWoJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "intercept = np.ones(n_subjects)\n",
        "design_matrix = pd.DataFrame(\n",
        "    np.vstack((age, sex, intercept)).T,\n",
        "    columns=[\"age\", \"sex\", \"intercept\"],\n",
        ")\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JELEtIebcWoJ"
      },
      "source": [
        "Let's plot the design matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR0xnQCEcWoK"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(1, 1, figsize=(4, 8))\n",
        "ax = plotting.plot_design_matrix(design_matrix, ax=ax1)\n",
        "ax.set_ylabel(\"maps\")\n",
        "fig.suptitle(\"Second level design matrix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ8_JWo_cWoK"
      },
      "source": [
        "Next, we specify and fit the second-level model when loading the data and\n",
        "also smooth a little bit to improve statistical behavior.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpnOXwjdcWoL"
      },
      "outputs": [],
      "source": [
        "from nilearn.glm.second_level import SecondLevelModel\n",
        "\n",
        "second_level_model = SecondLevelModel(\n",
        "    smoothing_fwhm=2.0, mask_img=mask_img, n_jobs=2\n",
        ")\n",
        "second_level_model.fit(\n",
        "    gray_matter_map_filenames,\n",
        "    design_matrix=design_matrix,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQfwiok8cWoM"
      },
      "source": [
        "Estimating the :term:`contrast` is very simple.\n",
        "We can just provide the column name of the design matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL2s_cU0cWoM"
      },
      "outputs": [],
      "source": [
        "z_map = second_level_model.compute_contrast(\n",
        "    second_level_contrast=[1, 0, 0],\n",
        "    output_type=\"z_score\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsqBRuiXcWoN"
      },
      "source": [
        "We threshold the second level :term:`contrast`\n",
        "at FDR-corrected p < 0.05 and plot it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY8J4q5mcWoN"
      },
      "outputs": [],
      "source": [
        "from nilearn.glm import threshold_stats_img\n",
        "\n",
        "_, threshold = threshold_stats_img(z_map, alpha=0.05, height_control=\"fdr\")\n",
        "print(f\"The FDR=.05-corrected threshold is: {threshold:03g}\")\n",
        "\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "display = plotting.plot_stat_map(\n",
        "    z_map,\n",
        "    threshold=threshold,\n",
        "    colorbar=True,\n",
        "    display_mode=\"z\",\n",
        "    cut_coords=[-4, 26],\n",
        "    figure=fig,\n",
        ")\n",
        "fig.suptitle(\"age effect on gray matter density (FDR = .05)\")\n",
        "plotting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9dXwbWocWoO"
      },
      "source": [
        "We can also study the effect of sex by computing the contrast, thresholding\n",
        "it and plot the resulting map.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p57v9EBAcWoO"
      },
      "outputs": [],
      "source": [
        "z_map = second_level_model.compute_contrast(\n",
        "    second_level_contrast=\"sex\",\n",
        "    output_type=\"z_score\",\n",
        ")\n",
        "_, threshold = threshold_stats_img(z_map, alpha=0.05, height_control=\"fdr\")\n",
        "plotting.plot_stat_map(\n",
        "    z_map,\n",
        "    threshold=threshold,\n",
        "    colorbar=True,\n",
        "    title=\"sex effect on gray matter density (FDR = .05)\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUZpkY21cWoP"
      },
      "source": [
        "Note that there does not seem to be any significant effect of sex on\n",
        "gray matter density on that dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFiGR4YtcWoQ"
      },
      "source": [
        "## Generating a report\n",
        "It can be useful to quickly generate a portable, ready-to-view report with\n",
        "most of the pertinent information.\n",
        "This is easy to do if you have a fitted model and the list of contrasts,\n",
        "which we do here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__ZyJ-9XcWoQ"
      },
      "outputs": [],
      "source": [
        "from nilearn.reporting import make_glm_report\n",
        "\n",
        "icbm152_2009 = datasets.fetch_icbm152_2009()\n",
        "report = make_glm_report(\n",
        "    model=second_level_model,\n",
        "    contrasts=[\"age\", \"sex\"],\n",
        "    bg_img=icbm152_2009[\"t1\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aniWqE5lcWoR"
      },
      "source": [
        "We have several ways to access the report:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il1YGkSBcWoS"
      },
      "outputs": [],
      "source": [
        "# report  # This report can be viewed in a notebook\n",
        "# report.open_in_browser()\n",
        "\n",
        "# or we can save as an html file\n",
        "# from pathlib import Path\n",
        "# output_dir = Path.cwd() / \"results\" / \"plot_oasis\"\n",
        "# output_dir.mkdir(exist_ok=True, parents=True)\n",
        "# report.save_as_html(output_dir / 'report.html')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

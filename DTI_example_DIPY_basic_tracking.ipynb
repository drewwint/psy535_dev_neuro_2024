{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drewwint/psy535_dev_neuro_2024/blob/main/DTI_example_DIPY_basic_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-m_M3RKbbMh"
      },
      "source": [
        "\n",
        "\n",
        "# Introduction to Basic Tracking\n",
        "\n",
        "Local fiber tracking is an approach used to model white matter fibers by\n",
        "creating streamlines from local directional information. The idea is as\n",
        "follows: if the local directionality of a tract/pathway segment is known, one\n",
        "can integrate along those directions to build a complete representation of that\n",
        "structure. Local fiber tracking is widely used in the field of diffusion MRI\n",
        "because it is simple and robust.\n",
        "\n",
        "In order to perform local fiber tracking, three things are needed::\n",
        "\n",
        "1. A method for getting directions from a diffusion dataset.\n",
        "2. A method for identifying when the tracking must stop.\n",
        "3. A set of seeds from which to begin tracking.\n",
        "\n",
        "This example shows how to combine the 3 parts described above\n",
        "to create a tractography reconstruction from a diffusion data set.\n",
        "\n",
        "Let's begin by importing the necessary modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMsHtucRbbMm"
      },
      "outputs": [],
      "source": [
        "from dipy.core.gradients import gradient_table\n",
        "from dipy.data import get_fnames, default_sphere\n",
        "from dipy.direction import peaks_from_model\n",
        "from dipy.io.gradients import read_bvals_bvecs\n",
        "from dipy.io.image import load_nifti, load_nifti_data\n",
        "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
        "from dipy.io.streamline import save_trk\n",
        "from dipy.reconst.csdeconv import auto_response_ssst\n",
        "from dipy.reconst.shm import CsaOdfModel\n",
        "from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion\n",
        "from dipy.tracking import utils\n",
        "from dipy.tracking.local_tracking import LocalTracking\n",
        "from dipy.tracking.streamline import Streamlines\n",
        "\n",
        "from dipy.viz import window, actor, has_fury, colormap\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2e0r8PbbbMn"
      },
      "source": [
        "Now, let's load an HARDI dataset from Stanford. If you have\n",
        "not already downloaded this data set, the first time you run this example you\n",
        "will need to be connected to the internet and this dataset will be downloaded\n",
        "to your computer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsWwl2XAbbMn"
      },
      "outputs": [],
      "source": [
        "# Enables/disables interactive visualization\n",
        "interactive = False\n",
        "\n",
        "hardi_fname, hardi_bval_fname, hardi_bvec_fname = get_fnames('stanford_hardi')\n",
        "label_fname = get_fnames('stanford_labels')\n",
        "\n",
        "data, affine, hardi_img = load_nifti(hardi_fname, return_img=True)\n",
        "labels = load_nifti_data(label_fname)\n",
        "bvals, bvecs = read_bvals_bvecs(hardi_bval_fname, hardi_bvec_fname)\n",
        "gtab = gradient_table(bvals, bvecs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu_YasaIbbMo"
      },
      "source": [
        "This dataset provides a label map in which all white matter tissues are\n",
        "labeled either 1 or 2. Let's create a white matter mask to restrict tracking\n",
        "to the white matter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaBDyXc0bbMo"
      },
      "outputs": [],
      "source": [
        "white_matter = (labels == 1) | (labels == 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1SBQWBZbbMp"
      },
      "source": [
        "## Step 1: Getting directions from a diffusion dataset\n",
        "\n",
        "The first thing we need to begin fiber tracking is a way of getting\n",
        "directions from this diffusion data set. In order to do that, we can fit the\n",
        "data to a Constant Solid Angle ODF Model. This model will estimate the\n",
        "Orientation Distribution Function (ODF) at each voxel. The ODF is the\n",
        "distribution of water diffusion as a function of direction. The peaks of an\n",
        "ODF are good estimates for the orientation of tract segments at a point in\n",
        "the image. Here, we use ``peaks_from_model`` to fit the data and calculate\n",
        "the fiber directions in all voxels of the white matter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2QzKCO_bbMp"
      },
      "outputs": [],
      "source": [
        "response, ratio = auto_response_ssst(gtab, data, roi_radii=10, fa_thr=0.7)\n",
        "csa_model = CsaOdfModel(gtab, sh_order=6)\n",
        "csa_peaks = peaks_from_model(csa_model, data, default_sphere,\n",
        "                             relative_peak_threshold=.8,\n",
        "                             min_separation_angle=45,\n",
        "                             mask=white_matter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQYlbtC_bbMq"
      },
      "source": [
        "For quality assurance we can also visualize a slice from the direction field\n",
        "which we will use as the basis to perform the tracking. The visualization\n",
        "will be done using the ``fury`` python package\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rycVHy9IbbMr"
      },
      "outputs": [],
      "source": [
        "if has_fury:\n",
        "    scene = window.Scene()\n",
        "    scene.add(actor.peak_slicer(csa_peaks.peak_dirs,\n",
        "                                csa_peaks.peak_values,\n",
        "                                colors=None))\n",
        "\n",
        "    window.record(scene, out_path='csa_direction_field.png', size=(900, 900))\n",
        "\n",
        "    if interactive:\n",
        "        window.show(scene, size=(800, 800))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYgRcThibbMs"
      },
      "source": [
        ".. rst-class:: centered small fst-italic fw-semibold\n",
        "\n",
        "Direction Field (peaks)\n",
        "\n",
        "\n",
        "## Step 2: Identifying when the tracking must stop\n",
        "Next we need some way of restricting the fiber tracking to areas with good\n",
        "directionality information. We've already created the white matter mask,\n",
        "but we can go a step further and restrict fiber tracking to those areas where\n",
        "the ODF shows significant restricted diffusion by thresholding on\n",
        "the generalized fractional anisotropy (GFA).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y11GbN-jbbMt"
      },
      "outputs": [],
      "source": [
        "stopping_criterion = ThresholdStoppingCriterion(csa_peaks.gfa, .25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls4hpO6BbbMt"
      },
      "source": [
        "Again, for quality assurance, we can also visualize a slice of the GFA and\n",
        "the resulting tracking mask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33tei1_xbbMu"
      },
      "outputs": [],
      "source": [
        "sli = csa_peaks.gfa.shape[2] // 2\n",
        "plt.figure('GFA')\n",
        "plt.subplot(1, 2, 1).set_axis_off()\n",
        "plt.imshow(csa_peaks.gfa[:, :, sli].T, cmap='gray', origin='lower')\n",
        "\n",
        "plt.subplot(1, 2, 2).set_axis_off()\n",
        "plt.imshow((csa_peaks.gfa[:, :, sli] > 0.25).T, cmap='gray', origin='lower')\n",
        "\n",
        "plt.savefig('gfa_tracking_mask.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl6pqxk4bbMu"
      },
      "source": [
        ".. rst-class:: centered small fst-italic fw-semibold\n",
        "\n",
        "An example of a tracking mask derived from the generalized fractional\n",
        "anisotropy (GFA).\n",
        "\n",
        "\n",
        "\n",
        "## Step 3: Defining a set of seeds from which to begin tracking\n",
        "Before we can begin tracking, we need to specify where to \"seed\" (begin)\n",
        "the fiber tracking. Generally, the seeds chosen will depend on the pathways\n",
        "one is interested in modeling. In this example, we'll use a\n",
        "$2 \\times 2 \\times 2$ grid of seeds per voxel, in a sagittal slice of the\n",
        "corpus callosum. Tracking from this region will give us a model of the\n",
        "corpus callosum tract. This slice has label value ``2`` in the label's image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG2RnYE8bbMv"
      },
      "outputs": [],
      "source": [
        "seed_mask = (labels == 2)\n",
        "seeds = utils.seeds_from_mask(seed_mask, affine, density=[2, 2, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb5SpdnibbMv"
      },
      "source": [
        "Finally, we can bring it all together using ``LocalTracking``, using\n",
        "the EuDX algorithm [Garyfallidis12]_. ``EuDX`` [Garyfallidis12]_ is a fast\n",
        "algorithm that we use here to generate streamlines. This algorithm is what is\n",
        "used here and the default option when providing the output of peaks directly\n",
        "in LocalTracking.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWjbVZQ2bbMv"
      },
      "outputs": [],
      "source": [
        "# Initialization of LocalTracking. The computation happens in the next step.\n",
        "streamlines_generator = LocalTracking(csa_peaks, stopping_criterion, seeds,\n",
        "                                      affine=affine, step_size=.5)\n",
        "# Generate streamlines object\n",
        "streamlines = Streamlines(streamlines_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLpzyEsBbbMv"
      },
      "source": [
        "We will then display the resulting streamlines using the ``fury``\n",
        "python package.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmiJaLi0bbMw"
      },
      "outputs": [],
      "source": [
        "if has_fury:\n",
        "    # Prepare the display objects.\n",
        "    color = colormap.line_colors(streamlines)\n",
        "\n",
        "    streamlines_actor = actor.line(streamlines,\n",
        "                                   colormap.line_colors(streamlines))\n",
        "\n",
        "    # Create the 3D display.\n",
        "    scene = window.Scene()\n",
        "    scene.add(streamlines_actor)\n",
        "\n",
        "    # Save still images for this static example. Or for interactivity use\n",
        "    window.record(scene, out_path='tractogram_EuDX.png', size=(800, 800))\n",
        "    if interactive:\n",
        "        window.show(scene)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rEuFUjlbbMw"
      },
      "source": [
        ".. rst-class:: centered small fst-italic fw-semibold\n",
        "\n",
        "Corpus Callosum using EuDx\n",
        "\n",
        "\n",
        "We've created a deterministic set of streamlines using the EuDX algorithm.\n",
        "This is so called deterministic because if you repeat the fiber tracking\n",
        "(keeping all the inputs the same) you will get exactly the same set of\n",
        "streamlines. We can save the streamlines as a Trackvis file so it can be\n",
        "loaded into other software for visualization or further analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6yc6B9FbbMw"
      },
      "outputs": [],
      "source": [
        "sft = StatefulTractogram(streamlines, hardi_img, Space.RASMM)\n",
        "save_trk(sft, \"tractogram_EuDX.trk\", streamlines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ6z449JbbMw"
      },
      "source": [
        "## References\n",
        ".. [Garyfallidis12] Garyfallidis E., \"Towards an accurate brain tractography\"\n",
        "PhD thesis, University of Cambridge, 2012.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtJQ3TW0bbMw"
      },
      "source": [
        ".. include:: ../../links_names.inc\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}